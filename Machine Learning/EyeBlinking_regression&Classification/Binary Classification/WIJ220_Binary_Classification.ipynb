{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***BINARY BLINKING CLASSIFICATION USING CEW DATASET***"
      ],
      "metadata": {
        "id": "sxk2bIaWTMDb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import required libraries"
      ],
      "metadata": {
        "id": "Yyd6V8NTTmcX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koo5YcRoRyOQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from tensorflow.keras import layers, models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining hyperparameters and loading the dataset"
      ],
      "metadata": {
        "id": "OnRcE0_jTre1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the paths to the train and validation data folders\n",
        "train_data_dir = '/content/drive/MyDrive/CEW/dataset/train'\n",
        "validation_data_dir = '/content/drive/MyDrive/CEW/dataset/val'\n",
        "\n",
        "# Set the input image dimensions\n",
        "img_width, img_height = 24, 24\n",
        "\n",
        "# Define the batch size and number of training epochs\n",
        "batch_size = 32\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "PsYWM3CplGOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "_lgiWL-VT1nt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation and normalization for the training set\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Normalization for the validation set\n",
        "validation_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "# Load and preprocess the training set\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Load and preprocess the validation set\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0axR6FdlmZg",
        "outputId": "dd3595e0-7711-4d6e-97d1-5ca9ff6ca703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3780 images belonging to 2 classes.\n",
            "Found 1068 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and Training the Model"
      ],
      "metadata": {
        "id": "QojeFYFmT7dq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN model architecture\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))  # Binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hXrAZxElwwk",
        "outputId": "07a184d8-1602-4ed5-a94b-d946c78235e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "118/118 [==============================] - 1655s 14s/step - loss: 0.5648 - accuracy: 0.6942 - val_loss: 0.4376 - val_accuracy: 0.7898\n",
            "Epoch 2/10\n",
            "118/118 [==============================] - 11s 90ms/step - loss: 0.3200 - accuracy: 0.8741 - val_loss: 0.2607 - val_accuracy: 0.9091\n",
            "Epoch 3/10\n",
            "118/118 [==============================] - 10s 87ms/step - loss: 0.2247 - accuracy: 0.9165 - val_loss: 0.2155 - val_accuracy: 0.9223\n",
            "Epoch 4/10\n",
            "118/118 [==============================] - 10s 86ms/step - loss: 0.1842 - accuracy: 0.9304 - val_loss: 0.1743 - val_accuracy: 0.9432\n",
            "Epoch 5/10\n",
            "118/118 [==============================] - 11s 97ms/step - loss: 0.1715 - accuracy: 0.9400 - val_loss: 0.1736 - val_accuracy: 0.9318\n",
            "Epoch 6/10\n",
            "118/118 [==============================] - 10s 88ms/step - loss: 0.1582 - accuracy: 0.9392 - val_loss: 0.1504 - val_accuracy: 0.9489\n",
            "Epoch 7/10\n",
            "118/118 [==============================] - 10s 86ms/step - loss: 0.1477 - accuracy: 0.9453 - val_loss: 0.1541 - val_accuracy: 0.9479\n",
            "Epoch 8/10\n",
            "118/118 [==============================] - 10s 85ms/step - loss: 0.1439 - accuracy: 0.9474 - val_loss: 0.1335 - val_accuracy: 0.9564\n",
            "Epoch 9/10\n",
            "118/118 [==============================] - 10s 88ms/step - loss: 0.1434 - accuracy: 0.9469 - val_loss: 0.1417 - val_accuracy: 0.9470\n",
            "Epoch 10/10\n",
            "118/118 [==============================] - 13s 109ms/step - loss: 0.1186 - accuracy: 0.9565 - val_loss: 0.1327 - val_accuracy: 0.9470\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f25d41e6b30>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the Model"
      ],
      "metadata": {
        "id": "1dprc15SUCRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(validation_generator)\n",
        "print(f'Validation Loss: {loss:.4f}')\n",
        "print(f'Validation Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlpzZI1yl3Lr",
        "outputId": "d536a3bd-9236-454d-fbb1-ef8b345d8a92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34/34 [==============================] - 2s 58ms/step - loss: 0.1313 - accuracy: 0.9476\n",
            "Validation Loss: 0.1313\n",
            "Validation Accuracy: 0.9476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics results"
      ],
      "metadata": {
        "id": "n6ba_zX_UH_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate precision, recall, and F1 score\n",
        "y_true = validation_generator.classes\n",
        "y_pred = model.predict(validation_generator)\n",
        "y_pred = (y_pred > 0.5).astype(int)\n",
        "\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq243fDATAek",
        "outputId": "5996b187-eec0-4162-f427-21f271c1f135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34/34 [==============================] - 2s 56ms/step\n",
            "Precision: 0.9310\n",
            "Recall: 0.9687\n",
            "F1 Score: 0.9495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predictions"
      ],
      "metadata": {
        "id": "Sl2Y2ckgUQnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# /content/drive/MyDrive/CEW/closedeye.jpg\n",
        "# /content/drive/MyDrive/CEW/openeye.jpg\n",
        "\n",
        "from PIL import Image\n",
        "# Load and preprocess the new eye image\n",
        "new_eye_image_path = '/content/drive/MyDrive/CEW/openeye.jpg'\n",
        "new_eye_image = Image.open(new_eye_image_path)\n",
        "new_eye_image = new_eye_image.resize((img_width, img_height))\n",
        "new_eye_image = np.array(new_eye_image)\n",
        "new_eye_image = new_eye_image.astype('float32') / 255.0\n",
        "# Make predictions on new eye images\n",
        "prediction = model.predict(np.expand_dims(new_eye_image, axis=0))\n",
        "if prediction > 0.5:\n",
        "    print(\"Blinking\")\n",
        "else:\n",
        "    print(\"Not blinking\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjYFQFkfl93g",
        "outputId": "14529a93-176d-4e3d-b1f1-76949f366648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 32ms/step\n",
            "Blinking\n"
          ]
        }
      ]
    }
  ]
}