{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe0wXS3hiivj"
      },
      "source": [
        "## Task Description"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1u5yNkBfinjb"
      },
      "source": [
        "#### implement a custom Autoencoder structure (that reconstrcuts images) and the forward function. \n",
        "\n",
        "#### Afterwards, make sure to run cell code number 1.2. to know if your implementation is correct.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMIcKSZ3i1ur"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztfR3038icfM"
      },
      "source": [
        "#### **NO GPU IS NEEDED for this task**. No training nor any computationally expensive operation will be performed. This notebook runs on any computer using a cpu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExK30uAjUaz9"
      },
      "outputs": [],
      "source": [
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #make sure that you are using GPU acceleration\n",
        "#device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jPxTombVv9L"
      },
      "source": [
        "## 1. Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vchO-YTwe38A"
      },
      "source": [
        "#### Please keep in mind that this architecture is purely imagined and should not correspond to any existing model / architecture. You will not find it on the internet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwkZf0__hy2U"
      },
      "source": [
        "Please right click the image and \"Open image in a new tab\" to view it better with zoom. Or download it from here: https://drive.google.com/file/d/1494LkXk3Sm1TDV8tN1E9jWGLcAKMkViA/view?usp=sharing\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1494LkXk3Sm1TDV8tN1E9jWGLcAKMkViA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtvGCndKhzhb"
      },
      "source": [
        "#### 1.1. Implement the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Wwn11gARdQr"
      },
      "outputs": [],
      "source": [
        "class Reconstruct(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(Reconstruct, self).__init__()\n",
        "\n",
        "        \n",
        "\n",
        "        # DEFINE the Convolution layers\n",
        "        self.Conv2D_1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(5, 5), stride=(2, 2), padding='valid')\n",
        "        self.Conv2D_2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), stride=(1, 1), padding='same')\n",
        "        self.Conv2D_3 = nn.Conv2d(in_channels=128, out_channels=512, kernel_size=(5, 5), stride=(3, 3), padding='valid')\n",
        "        self.Conv2D_4 = nn.Conv2d(in_channels=640, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding='same')\n",
        "        # DEFINE the MaxPooling layers\n",
        "        self.MaxPooling_1 = nn.MaxPool2d(kernel_size=(7, 7), stride=(2, 2))\n",
        "        self.MaxPooling_2 = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2))  \n",
        "        # DEFINE the Transposed Convolution layers\n",
        "        self.transposed_1 = nn.ConvTranspose2d(in_channels=512, out_channels=512, kernel_size=(14, 14), stride=(7, 7), padding=2)\n",
        "        self.transposed_2 = nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=(8, 8), stride=(2, 2), padding=0)\n",
        "        self.transposed_3 = nn.ConvTranspose2d(in_channels=320, out_channels=3, kernel_size=(6, 6), stride=(2, 2), padding=0)\n",
        "         \n",
        "        \n",
        "    def forward(self, images):\n",
        "\n",
        "        # SEND the input to the convolutional and max pooling layers\n",
        "        out1 = self.Conv2D_1(images)\n",
        "        out2 = self.MaxPooling_1(out1)\n",
        "        out3 = self.Conv2D_2(out2)\n",
        "        out4 = self.MaxPooling_2(out3)\n",
        "        # SEND the features from the previous layers to the convolutional and transposed convolutional layers.\n",
        "        # Combine the outputs.\n",
        "        out5 = self.Conv2D_3(out4)\n",
        "        out6 = self.transposed_1(out5)\n",
        "        combination1 = torch.cat((out3,out6), dim=1)\n",
        "        out7 = self.Conv2D_4(combination1)\n",
        "        out8 = self.transposed_2(out7)\n",
        "        combination2 = torch.cat((out1, out8), dim=1)\n",
        "        out = self.transposed_3(combination2)\n",
        "        return out #replace by actual output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJqVLXTqJR7p"
      },
      "source": [
        "#### 1.2. Test your implementation.\n",
        "Expected output \n",
        "\n",
        "torch.Size( [1, 3, 224, 224] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLuor1bCJRKf",
        "outputId": "9455f67d-6ebd-440b-e77e-e8cf45ae7f78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your output shape is  torch.Size([1, 3, 224, 224])\n",
            "Your implementation is CORRECT!\n"
          ]
        }
      ],
      "source": [
        "input_image = torch.randn(1,3,224,224)\n",
        "\n",
        "custom = Reconstruct()\n",
        "output = custom(input_image)\n",
        "\n",
        "print(\"Your output shape is \", output.shape)\n",
        "\n",
        "assert output.shape == input_image.shape , \"Your implementation is INCORRECT!\"\n",
        "\n",
        "print(\"Your implementation is CORRECT!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of _Exam_01_06_2022_2PM_Part1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
