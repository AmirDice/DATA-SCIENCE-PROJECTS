{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "U-Net implementation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing U-Net layers with PyTorch"
      ],
      "metadata": {
        "id": "V10FOjt2183T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlPCwrW41wWD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set up GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6b_HvUg4qE4",
        "outputId": "559c9225-e298-45e5-fc8a-f08fd944d9d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# U-Net architecture\n",
        "\n",
        "<img src=\"https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png\" style=\"max-width:400px;\">"
      ],
      "metadata": {
        "id": "kwqIteaw2e_r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper functions"
      ],
      "metadata": {
        "id": "w_eq458G2-2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#double 3x3 convolution \n",
        "def dual_conv(in_channel, out_channel):\n",
        "    conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channel, out_channel, kernel_size=3),\n",
        "        nn.ReLU(inplace= True),\n",
        "        nn.Conv2d(out_channel, out_channel, kernel_size=3),\n",
        "        nn.ReLU(inplace= True),\n",
        "    )\n",
        "    return conv"
      ],
      "metadata": {
        "id": "SB1G_dAx22ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# crop the image(tensor) to equal size \n",
        "def crop_tensor(target_tensor, tensor):\n",
        "    target_size = target_tensor.size()[2]\n",
        "    tensor_size = tensor.size()[2]\n",
        "    delta = tensor_size - target_size\n",
        "    delta = delta // 2\n",
        "\n",
        "    return tensor[:, :, delta:tensor_size- delta, delta:tensor_size-delta]"
      ],
      "metadata": {
        "id": "a4RTiJOL3BSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining U-Net architecture"
      ],
      "metadata": {
        "id": "FsgoAuEO3QGe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "List of classes:\n",
        "https://github.com/CSAILVision/sceneparsing/blob/master/objectInfo150.csv"
      ],
      "metadata": {
        "id": "9SpLqRY-JZ5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#As an example, let's implement it for the MIT Scene Parsing dataset, which has 150 classes\n",
        "n_classes = 150"
      ],
      "metadata": {
        "id": "qlESE5LO4Kkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Unet(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super(Unet, self).__init__()\n",
        "\n",
        "        # Left side (contracting path)\n",
        "        self.dwn_conv1 = dual_conv(3, 64)\n",
        "        self.dwn_conv2 = dual_conv(64, 128)\n",
        "        self.dwn_conv3 = dual_conv(128, 256)\n",
        "        self.dwn_conv4 = dual_conv(256, 512)\n",
        "        self.dwn_conv5 = dual_conv(512, 1024)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        #Right side  (expnsion path) \n",
        "        #transpose convolution is used showna as green arrow in architecture image\n",
        "        self.trans1 = nn.ConvTranspose2d(1024,512, kernel_size=2, stride= 2)\n",
        "        self.up_conv1 = dual_conv(1024,512)\n",
        "        self.trans2 = nn.ConvTranspose2d(512,256, kernel_size=2, stride= 2)\n",
        "        self.up_conv2 = dual_conv(512,256)\n",
        "        self.trans3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride= 2)\n",
        "        self.up_conv3 = dual_conv(256,128)\n",
        "        self.trans4 = nn.ConvTranspose2d(128,64, kernel_size=2, stride= 2)\n",
        "        self.up_conv4 = dual_conv(128,64)\n",
        "\n",
        "        #output layer\n",
        "        self.out = nn.Conv2d(64, n_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, image):\n",
        "\n",
        "        #forward pass for Left side\n",
        "        x1 = self.dwn_conv1(image)\n",
        "        x2 = self.maxpool(x1)\n",
        "        x3 = self.dwn_conv2(x2)\n",
        "        x4 = self.maxpool(x3)\n",
        "        x5 = self.dwn_conv3(x4)\n",
        "        x6 = self.maxpool(x5)\n",
        "        x7 = self.dwn_conv4(x6)\n",
        "        x8 = self.maxpool(x7)\n",
        "        x9 = self.dwn_conv5(x8)\n",
        "        \n",
        "\n",
        "        #forward pass for Right side\n",
        "        x = self.trans1(x9)\n",
        "        y = crop_tensor(x, x7)\n",
        "        x = self.up_conv1(torch.cat([x,y], 1))\n",
        "\n",
        "        x = self.trans2(x)\n",
        "        y = crop_tensor(x, x5)\n",
        "        x = self.up_conv2(torch.cat([x,y], 1))\n",
        "\n",
        "        x = self.trans3(x)\n",
        "        y = crop_tensor(x, x3)\n",
        "        x = self.up_conv3(torch.cat([x,y], 1))\n",
        "\n",
        "        x = self.trans4(x)\n",
        "        y = crop_tensor(x, x1)\n",
        "        x = self.up_conv4(torch.cat([x,y], 1))\n",
        "        \n",
        "        x = self.out(x)\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "hXD5TTo33MVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "unet = Unet(n_classes).to(device)\n",
        "summary(unet, (3,572,572))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nbRU9b63ofC",
        "outputId": "b75d25e3-6ffd-44c1-c4f9-f9b5631bf842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 570, 570]           1,792\n",
            "              ReLU-2         [-1, 64, 570, 570]               0\n",
            "            Conv2d-3         [-1, 64, 568, 568]          36,928\n",
            "              ReLU-4         [-1, 64, 568, 568]               0\n",
            "         MaxPool2d-5         [-1, 64, 284, 284]               0\n",
            "            Conv2d-6        [-1, 128, 282, 282]          73,856\n",
            "              ReLU-7        [-1, 128, 282, 282]               0\n",
            "            Conv2d-8        [-1, 128, 280, 280]         147,584\n",
            "              ReLU-9        [-1, 128, 280, 280]               0\n",
            "        MaxPool2d-10        [-1, 128, 140, 140]               0\n",
            "           Conv2d-11        [-1, 256, 138, 138]         295,168\n",
            "             ReLU-12        [-1, 256, 138, 138]               0\n",
            "           Conv2d-13        [-1, 256, 136, 136]         590,080\n",
            "             ReLU-14        [-1, 256, 136, 136]               0\n",
            "        MaxPool2d-15          [-1, 256, 68, 68]               0\n",
            "           Conv2d-16          [-1, 512, 66, 66]       1,180,160\n",
            "             ReLU-17          [-1, 512, 66, 66]               0\n",
            "           Conv2d-18          [-1, 512, 64, 64]       2,359,808\n",
            "             ReLU-19          [-1, 512, 64, 64]               0\n",
            "        MaxPool2d-20          [-1, 512, 32, 32]               0\n",
            "           Conv2d-21         [-1, 1024, 30, 30]       4,719,616\n",
            "             ReLU-22         [-1, 1024, 30, 30]               0\n",
            "           Conv2d-23         [-1, 1024, 28, 28]       9,438,208\n",
            "             ReLU-24         [-1, 1024, 28, 28]               0\n",
            "  ConvTranspose2d-25          [-1, 512, 56, 56]       2,097,664\n",
            "           Conv2d-26          [-1, 512, 54, 54]       4,719,104\n",
            "             ReLU-27          [-1, 512, 54, 54]               0\n",
            "           Conv2d-28          [-1, 512, 52, 52]       2,359,808\n",
            "             ReLU-29          [-1, 512, 52, 52]               0\n",
            "  ConvTranspose2d-30        [-1, 256, 104, 104]         524,544\n",
            "           Conv2d-31        [-1, 256, 102, 102]       1,179,904\n",
            "             ReLU-32        [-1, 256, 102, 102]               0\n",
            "           Conv2d-33        [-1, 256, 100, 100]         590,080\n",
            "             ReLU-34        [-1, 256, 100, 100]               0\n",
            "  ConvTranspose2d-35        [-1, 128, 200, 200]         131,200\n",
            "           Conv2d-36        [-1, 128, 198, 198]         295,040\n",
            "             ReLU-37        [-1, 128, 198, 198]               0\n",
            "           Conv2d-38        [-1, 128, 196, 196]         147,584\n",
            "             ReLU-39        [-1, 128, 196, 196]               0\n",
            "  ConvTranspose2d-40         [-1, 64, 392, 392]          32,832\n",
            "           Conv2d-41         [-1, 64, 390, 390]          73,792\n",
            "             ReLU-42         [-1, 64, 390, 390]               0\n",
            "           Conv2d-43         [-1, 64, 388, 388]          36,928\n",
            "             ReLU-44         [-1, 64, 388, 388]               0\n",
            "           Conv2d-45        [-1, 150, 388, 388]           9,750\n",
            "================================================================\n",
            "Total params: 31,041,430\n",
            "Trainable params: 31,041,430\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 3.74\n",
            "Forward/backward pass size (MB): 2141.85\n",
            "Params size (MB): 118.41\n",
            "Estimated Total Size (MB): 2264.00\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}